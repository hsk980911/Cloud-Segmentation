{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJ_5vemHnXlZ"
   },
   "source": [
    "구글 드라이브 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g-1-veNcnW6U",
    "outputId": "1aeb2940-0bdd-448c-ed96-0baf7b8d0064"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1NrfEiTnlLS"
   },
   "source": [
    "폴더 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9oW1RJXWnkxw"
   },
   "outputs": [],
   "source": [
    "# workspace_path = '/gdrive/My Drive/Colab Notebooks/CV2022/competition'  # 파일 업로드한 경로 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = '/app/HSK/CV'  # 파일 업로드한 경로 반영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86ea40c7"
   },
   "source": [
    "### 필요한 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lRfwuEL2--n-",
    "outputId": "f58dedc2-f681-43bc-9d8d-3e01a7d9195e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations==0.4.6 in /home/user/.local/lib/python3.8/site-packages (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.22.2)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (6.0)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (0.4.0)\n",
      "Requirement already satisfied: scipy in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (4.5.5.64)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.19.2)\n",
      "Requirement already satisfied: Pillow in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.5.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.14.0)\n",
      "Requirement already satisfied: Shapely in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n",
      "Requirement already satisfied: imageio in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.19.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2022.5.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yacs in /home/user/.local/lib/python3.8/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from yacs) (6.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install albumentations==0.4.6\n",
    "!pip install yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "52bbfdfb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter \n",
    "\n",
    "tb_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "649609b1"
   },
   "source": [
    "### 재구현 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c35eec19"
   },
   "outputs": [],
   "source": [
    "def init_seeds(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    if seed == 0:  # slower, more reproducible\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = False\n",
    "    else:  # faster, less reproducible\n",
    "        cudnn.deterministic = False\n",
    "        cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "b90c4ec5"
   },
   "outputs": [],
   "source": [
    "init_seeds(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f8a343a"
   },
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "499b3f23"
   },
   "outputs": [],
   "source": [
    "rgb_path = os.path.join(workspace_path, 'data/train/rgb/')\n",
    "ngr_path = os.path.join(workspace_path, 'data/train/ngr/')\n",
    "label_path = os.path.join(workspace_path, 'data/train/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d4e26b49"
   },
   "outputs": [],
   "source": [
    "rgb_images = os.listdir(rgb_path)\n",
    "rgb_images = [os.path.join(rgb_path,x) for x in rgb_images]\n",
    "ngr_images = os.listdir(ngr_path)\n",
    "ngr_images = [os.path.join(ngr_path, x) for x in ngr_images]\n",
    "label_images = os.listdir(label_path)\n",
    "label_images = [os.path.join(label_path, x) for x in label_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997d5237"
   },
   "source": [
    "### 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ca96420c"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09d79e8b"
   },
   "source": [
    "### 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "a6ac4eae"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 10\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "patch_size = 400\n",
    "patch_stride = 100\n",
    "num_workers = 0\n",
    "\n",
    "num_classes = 4\n",
    "class_names = ['thick cloud', 'thin cloud', 'cloud shadow']\n",
    "\n",
    "train_data_rate = 0.7\n",
    "\n",
    "model_name = 'hrnet_w48'\n",
    "\n",
    "loss_func = 'dice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e4513b1"
   },
   "source": [
    "### 데이터증대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "17dc2c12"
   },
   "outputs": [],
   "source": [
    "class ImageAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.HorizontalFlip(p=0.5),\n",
    "                             A.VerticalFlip(p=0.5),\n",
    "                             A.ShiftScaleRotate(p=0.5),\n",
    "                             A.RandomBrightnessContrast(p=0.3),\n",
    "                             A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']\n",
    "\n",
    "class DefaultAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "03a59423"
   },
   "outputs": [],
   "source": [
    "train_transforms = ImageAug()\n",
    "val_transforms = DefaultAug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2147f462"
   },
   "source": [
    "### 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "98bed485"
   },
   "outputs": [],
   "source": [
    "#train dataset\n",
    "train_dataset = CloudDataset(rgb_images[:int(len(rgb_images)*train_data_rate)], label_images[:int(len(label_images)*train_data_rate)],\n",
    "                            transforms=train_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "#valid dataset\n",
    "val_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate):], label_images[int(len(label_images)*train_data_rate):],\n",
    "                            transforms=val_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cbab53"
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e54a2c7d"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gWNuzVTfzGUf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import functools\n",
    "\n",
    "import torch._utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BatchNorm2d = functools.partial(nn.BatchNorm2d)\n",
    "# BatchNorm2d = nn.SynchBatchNorm(InPlaceABNSync, activation='none')\n",
    "\n",
    "BN_MOMENTUM = 0.01\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = BatchNorm2d(planes * self.expansion,\n",
    "                               momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self._check_branches(\n",
    "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
    "                num_branches, len(num_blocks))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
    "                num_branches, len(num_channels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
    "                num_branches, len(num_inchannels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "                self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.num_inchannels[branch_index],\n",
    "                          num_channels[branch_index] * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm2d(num_channels[branch_index] * block.expansion,\n",
    "                            momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index],\n",
    "                            num_channels[branch_index], stride, downsample))\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index],\n",
    "                                num_channels[branch_index]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j],\n",
    "                                  num_inchannels[i],\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  0,\n",
    "                                  bias=False),\n",
    "                        BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i - j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM)))\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM),\n",
    "                                nn.ReLU(inplace=False)))\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                elif j > i:\n",
    "                    width_output = x[i].shape[-1]\n",
    "                    height_output = x[i].shape[-2]\n",
    "                    y = y + F.interpolate(\n",
    "                        self.fuse_layers[i][j](x[j]),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=False)\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse\n",
    "\n",
    "\n",
    "blocks_dict = {\n",
    "    'BASIC': BasicBlock,\n",
    "    'BOTTLENECK': Bottleneck\n",
    "}\n",
    "\n",
    "\n",
    "class HighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        extra = config.MODEL.EXTRA\n",
    "        super(HighResolutionNet, self).__init__()\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "        self.stage1_cfg = extra['STAGE1']\n",
    "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
    "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
    "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
    "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
    "        stage1_out_channel = block.expansion * num_channels\n",
    "\n",
    "        self.stage2_cfg = extra['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition1 = self._make_transition_layer(\n",
    "            [stage1_out_channel], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = extra['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = extra['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
    "\n",
    "        last_inp_channels = np.int(np.sum(pre_stage_channels))\n",
    "\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=last_inp_channels,\n",
    "                out_channels=last_inp_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0),\n",
    "            BatchNorm2d(last_inp_channels, momentum=BN_MOMENTUM),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(\n",
    "                in_channels=last_inp_channels,\n",
    "                out_channels=config.DATASET.NUM_CLASSES,\n",
    "                kernel_size=extra.FINAL_CONV_KERNEL,\n",
    "                stride=1,\n",
    "                padding=1 if extra.FINAL_CONV_KERNEL == 3 else 0)\n",
    "        )\n",
    "\n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i],\n",
    "                                  num_channels_cur_layer[i],\n",
    "                                  3,\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  bias=False),\n",
    "                        BatchNorm2d(\n",
    "                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=False)))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i + 1 - num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i - num_branches_pre else inchannels\n",
    "                    conv3x3s.append(nn.Sequential(\n",
    "                        nn.Conv2d(\n",
    "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
    "                        BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=False)))\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "            modules.append(\n",
    "                HighResolutionModule(num_branches,\n",
    "                                     block,\n",
    "                                     num_blocks,\n",
    "                                     num_inchannels,\n",
    "                                     num_channels,\n",
    "                                     fuse_method,\n",
    "                                     reset_multi_scale_output)\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                if i < self.stage2_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition2[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                if i < self.stage3_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition3[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        x = self.stage4(x_list)\n",
    "\n",
    "        # Upsampling\n",
    "        x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
    "        x1 = F.interpolate(x[1], size=(x0_h, x0_w), mode='bilinear', align_corners=False)\n",
    "        x2 = F.interpolate(x[2], size=(x0_h, x0_w), mode='bilinear', align_corners=False)\n",
    "        x3 = F.interpolate(x[3], size=(x0_h, x0_w), mode='bilinear', align_corners=False)\n",
    "\n",
    "        x = torch.cat([x[0], x1, x2, x3], 1)\n",
    "\n",
    "        x = self.last_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def init_weights(self, pretrained='', ):\n",
    "        logger.info('=> init weights from normal distribution')\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = torch.load(pretrained)\n",
    "            logger.info('=> loading pretrained model {}'.format(pretrained))\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                               if k in model_dict.keys()}\n",
    "            for k, _ in pretrained_dict.items():\n",
    "                logger.info(\n",
    "                    '=> loading {} pretrained model {}'.format(k, pretrained))\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "def get_seg_model(cfg, **kwargs):\n",
    "    model = HighResolutionNet(cfg, **kwargs)\n",
    "    model.init_weights(cfg.MODEL.PRETRAINED)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1e3d9a09"
   },
   "outputs": [],
   "source": [
    "# method for hrnet init\n",
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "_C = CN()\n",
    "\n",
    "_C.OUTPUT_DIR = ''\n",
    "_C.LOG_DIR = ''\n",
    "_C.GPUS = (0,)\n",
    "_C.WORKERS = 4\n",
    "_C.PRINT_FREQ = 20\n",
    "_C.AUTO_RESUME = False\n",
    "_C.PIN_MEMORY = True\n",
    "_C.RANK = 0\n",
    "\n",
    "# Cudnn related params\n",
    "_C.CUDNN = CN()\n",
    "_C.CUDNN.BENCHMARK = True\n",
    "_C.CUDNN.DETERMINISTIC = False\n",
    "_C.CUDNN.ENABLED = True\n",
    "\n",
    "# common params for NETWORK\n",
    "_C.MODEL = CN()\n",
    "_C.MODEL.NAME = 'seg_hrnet'\n",
    "_C.MODEL.PRETRAINED = ''\n",
    "_C.MODEL.EXTRA = CN(new_allowed=True)\n",
    "\n",
    "_C.LOSS = CN()\n",
    "_C.LOSS.USE_OHEM = False\n",
    "_C.LOSS.OHEMTHRES = 0.9\n",
    "_C.LOSS.OHEMKEEP = 100000\n",
    "_C.LOSS.CLASS_BALANCE = True\n",
    "\n",
    "# DATASET related params\n",
    "_C.DATASET = CN()\n",
    "_C.DATASET.ROOT = ''\n",
    "_C.DATASET.DATASET = 'cityscapes'\n",
    "_C.DATASET.NUM_CLASSES = 19\n",
    "_C.DATASET.TRAIN_SET = 'list/cityscapes/train.lst'\n",
    "_C.DATASET.EXTRA_TRAIN_SET = ''\n",
    "_C.DATASET.TEST_SET = 'list/cityscapes/val.lst'\n",
    "\n",
    "# training\n",
    "_C.TRAIN = CN()\n",
    "\n",
    "_C.TRAIN.IMAGE_SIZE = [1024, 512]  # width * height\n",
    "_C.TRAIN.BASE_SIZE = 2048\n",
    "_C.TRAIN.DOWNSAMPLERATE = 1\n",
    "_C.TRAIN.FLIP = True\n",
    "_C.TRAIN.MULTI_SCALE = True\n",
    "_C.TRAIN.SCALE_FACTOR = 16\n",
    "\n",
    "_C.TRAIN.LR_FACTOR = 0.1\n",
    "_C.TRAIN.LR_STEP = [90, 110]\n",
    "_C.TRAIN.LR = 0.01\n",
    "_C.TRAIN.EXTRA_LR = 0.001\n",
    "\n",
    "_C.TRAIN.OPTIMIZER = 'sgd'\n",
    "_C.TRAIN.MOMENTUM = 0.9\n",
    "_C.TRAIN.WD = 0.0001\n",
    "_C.TRAIN.NESTEROV = False\n",
    "_C.TRAIN.IGNORE_LABEL = -1\n",
    "\n",
    "_C.TRAIN.BEGIN_EPOCH = 0\n",
    "_C.TRAIN.END_EPOCH = 484\n",
    "_C.TRAIN.EXTRA_EPOCH = 0\n",
    "\n",
    "_C.TRAIN.RESUME = False\n",
    "\n",
    "_C.TRAIN.BATCH_SIZE_PER_GPU = 32\n",
    "_C.TRAIN.SHUFFLE = True\n",
    "# only using some training samples\n",
    "_C.TRAIN.NUM_SAMPLES = 0\n",
    "\n",
    "# testing\n",
    "_C.TEST = CN()\n",
    "\n",
    "_C.TEST.IMAGE_SIZE = [2048, 1024]  # width * height\n",
    "_C.TEST.BASE_SIZE = 2048\n",
    "\n",
    "_C.TEST.BATCH_SIZE_PER_GPU = 32\n",
    "# only testing some samples\n",
    "_C.TEST.NUM_SAMPLES = 0\n",
    "\n",
    "_C.TEST.MODEL_FILE = ''\n",
    "_C.TEST.FLIP_TEST = False\n",
    "_C.TEST.MULTI_SCALE = False\n",
    "_C.TEST.SCALE_LIST = [1]\n",
    "\n",
    "# debug\n",
    "_C.DEBUG = CN()\n",
    "_C.DEBUG.DEBUG = False\n",
    "_C.DEBUG.SAVE_BATCH_IMAGES_GT = False\n",
    "_C.DEBUG.SAVE_BATCH_IMAGES_PRED = False\n",
    "_C.DEBUG.SAVE_HEATMAPS_GT = False\n",
    "_C.DEBUG.SAVE_HEATMAPS_PRED = False\n",
    "\n",
    "\n",
    "def update_config(file):\n",
    "    cfg = _C.clone()\n",
    "    cfg.defrost()\n",
    "    cfg.merge_from_file(file)\n",
    "    cfg.freeze()\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "78338b36",
    "outputId": "0c6e4902-ac7e-4e22-b79f-a6af6efaebcf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1186837/3735718659.py:304: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  last_inp_channels = np.int(np.sum(pre_stage_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  65848564\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "if model_name == 'deeplabv3':\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=4)\n",
    "elif model_name == 'hrnet_w18':\n",
    "    hrnet_cfg = update_config(os.path.join(workspace_path, 'hrnet_w18_config.yaml'))\n",
    "    model = get_seg_model(hrnet_cfg)\n",
    "elif model_name == 'hrnet_w48':\n",
    "    hrnet_cfg = update_config(os.path.join(workspace_path, 'hrnet_w48_config.yaml'))\n",
    "    model = get_seg_model(hrnet_cfg)\n",
    "elif model_name == 'dilated_unet':\n",
    "    model = MyDilatedConvUNet()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('number of parameters: ', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "467743f7"
   },
   "source": [
    "### Opimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "314acf1e"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuJfaks1zbtC"
   },
   "source": [
    "### 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "c124f5df"
   },
   "outputs": [],
   "source": [
    "def fitness_test(true, pred, num_classes=4):\n",
    "    eps = 1e-7\n",
    "    true_one_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_one_hot = true_one_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "    pred_max = pred.argmax(1)      # (B, C, H, W) to (B, H, W)\n",
    "    pix_acc = (true == pred_max.unsqueeze(1)).sum().float().div(true.nelement())\n",
    "    pred_one_hot = F.one_hot(pred_max, num_classes=num_classes)   # (B, H, W) to (B, H, W, C)\n",
    "    pred_one_hot = pred_one_hot.permute(0, 3, 1, 2)   # (B, H, W, C) to (B, C, H, W)\n",
    "\n",
    "    true_one_hot = true_one_hot.type(pred_one_hot.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))  # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(pred_one_hot & true_one_hot, dims)\n",
    "    union = torch.sum(pred_one_hot | true_one_hot, dims)\n",
    "    m_iou = (intersection / (union + eps)).mean()\n",
    "\n",
    "    return m_iou.item(), pix_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "v74FWycdzdev"
   },
   "outputs": [],
   "source": [
    "# Loss 함수 정의\n",
    "def ce_loss(true, logits, ignore=255):\n",
    "    \"\"\"Computes the weighted multi-class cross-entropy loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        ignore: the class index to ignore.\n",
    "    Returns:\n",
    "        ce_loss: the weighted multi-class cross-entropy loss.\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(\n",
    "        logits.float(),\n",
    "        true.squeeze(1).long(),    # [B, H, W]\n",
    "        ignore_index=ignore,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        # true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))        # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "def jaccard_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d1af165"
   },
   "source": [
    "### 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bad17d99"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=400, use_scheduler=False, save_path='./ckpt_hrnet'):\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    if use_scheduler:\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "    start_epoch = 0\n",
    "    resume = True\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    weight_file = save_path + '/{}.pt'.format(model_name)\n",
    "\n",
    "    best_fit = 0.0\n",
    "    num_epochs = epochs\n",
    "\n",
    "    if resume:\n",
    "        if os.path.exists(weight_file):\n",
    "            checkpoint = torch.load(weight_file)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_fit = checkpoint['best_fit']\n",
    "            print(\"Starting training for %g epochs...\" % start_epoch)\n",
    "\n",
    "    # Start training\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        # loss, metric = train_one_epoch(model, optimizer, dataloader, device, epoch)\n",
    "        t0 = time.time()\n",
    "        loss = train_one_epoch(model, optimizer, train_dataloader, loss_func, device, epoch, num_epochs)\n",
    "        t1 = time.time()\n",
    "        print('[Epoch %g] loss=%.4f, time=%.1f' % (epoch, loss.item(), t1 - t0))\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step(loss)\n",
    "        tb_writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        state = {'model_name': model_name, 'epoch': epoch, 'best_fit': best_fit, 'model': model.state_dict()}\n",
    "        torch.save(state, weight_file)\n",
    "\n",
    "        tb_writer.add_scalar('train_epoch_loss', loss, epoch)\n",
    "\n",
    "        # validation\n",
    "        patch_size = patch_size\n",
    "        fit = val_one_epoch(model, val_dataloader, device, epoch, num_epochs, patch_size)\n",
    "        if fit > best_fit:\n",
    "            print(\"best fit so far=>saved\")\n",
    "            torch.save(state, os.path.join(save_path, '{}_best.pt'.format(model_name)))\n",
    "            best_fit = fit\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, loss_func, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    losses = np.array([])\n",
    "    metrics = np.array([])\n",
    "    bi0 = epoch * len(data_loader)  # batch index\n",
    "\n",
    "    print(('\\n' + '%10s' * 2) % ('Epoch', 'loss'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0)\n",
    "    pbar.set_description(s)\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        if model_name == 'deeplabv3':\n",
    "            preds = model(imgs)['out']\n",
    "            targets = targets.long()\n",
    "        elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "            preds = model(imgs)\n",
    "            h, w = preds.shape[2], preds.shape[3]\n",
    "#             print(preds.shape)\n",
    "#             print(targets.shape)\n",
    "#             print(preds)\n",
    "#             print(targets)\n",
    "            targets = targets.reshape(8,1,targets.shape[1],targets.shape[2])\n",
    "            targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n",
    "        elif model_name == 'dilated_unet':\n",
    "            preds = model(imgs)\n",
    "            targets = targets.long()\n",
    "            \n",
    "        if loss_func == 'jaccard':\n",
    "            loss = jaccard_loss(targets, preds)\n",
    "        elif loss_func == 'dice':\n",
    "            loss = dice_loss(targets, preds)\n",
    "        elif loss_func == 'ce':\n",
    "            loss = ce_loss(targets, preds)\n",
    "        else:\n",
    "            print('unsupported loss function')\n",
    "            exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # cv2_imshow(imgs[0], preds[0])\n",
    "            losses = np.append(losses, loss.item())\n",
    "\n",
    "            s = ('%10s' + '%10.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), loss.item())\n",
    "            pbar.set_description(s)\n",
    "            bi = bi0 + i\n",
    "            tb_writer.add_scalar('train_batch_loss', loss.item(), bi)\n",
    "\n",
    "    epoch_loss = losses.mean()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def val_one_epoch(model, data_loader, device, epoch, num_epochs, patch_size):\n",
    "    model.eval()\n",
    "    m_iou_list = np.array([])\n",
    "    pix_acc_list = np.array([])\n",
    "\n",
    "    print(('\\n' + '%10s' * 3) % ('Epoch(V)', 'mIOU', 'Accuracy'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0, 0.0)\n",
    "    pbar.set_description(s)\n",
    "\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            if model_name == 'deeplabv3':\n",
    "                preds = model(imgs)['out']\n",
    "                targets = targets.long()\n",
    "            elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "                preds = model(imgs)\n",
    "                h, w = preds.shape[2], preds.shape[3]\n",
    "                targets = targets.reshape(8,1,targets.shape[1],targets.shape[2])\n",
    "                targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n",
    "            elif model_name == 'dilated_unet':\n",
    "                preds = model(imgs)\n",
    "                targets = targets.long()\n",
    "\n",
    "            m_iou, pix_acc = fitness_test(targets, preds)\n",
    "\n",
    "            s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), m_iou, pix_acc)\n",
    "            pbar.set_description(s)\n",
    "            m_iou_list = np.append(m_iou_list, m_iou)\n",
    "            pix_acc_list = np.append(pix_acc_list, pix_acc)\n",
    "    val_m_iou_mean = m_iou_list.mean()\n",
    "    val_pix_acc_mean = pix_acc_list.mean()\n",
    "    print('[V] mIOU={:.3f}, Accuracy={:.3f}'.format(val_m_iou_mean, val_pix_acc_mean))\n",
    "    tb_writer.add_scalar('val_epoch_m_iou', val_m_iou_mean, epoch)\n",
    "    tb_writer.add_scalar('val_epoch_pix_acc', val_pix_acc_mean, epoch)\n",
    "    return val_pix_acc_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "600d9790"
   },
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "b74e3dff",
    "outputId": "b4ce8779-71be-4428-a357-78010400d46a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0/9    0.5023: 100%|█████████████████| 3552/3552 [36:16<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] loss=0.5617, time=2176.3\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0/9    0.3364   0.4908: 100%|████████| 1525/1525 [09:21<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.381, Accuracy=0.587\n",
      "best fit so far=>saved\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/9    0.4067: 100%|█████████████████| 3552/3552 [36:46<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.5106, time=2206.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/9    0.4618   0.6939: 100%|████████| 1525/1525 [09:21<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.418, Accuracy=0.643\n",
      "best fit so far=>saved\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/9    0.3669: 100%|█████████████████| 3552/3552 [36:52<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.4695, time=2212.8\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/9    0.4898   0.6420: 100%|████████| 1525/1525 [09:24<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.463, Accuracy=0.671\n",
      "best fit so far=>saved\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/9    0.4750: 100%|█████████████████| 3552/3552 [37:29<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.4385, time=2249.8\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/9    0.4145   0.6137: 100%|████████| 1525/1525 [09:22<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.469, Accuracy=0.688\n",
      "best fit so far=>saved\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/9    0.5771: 100%|█████████████████| 3552/3552 [36:52<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] loss=0.4161, time=2212.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/9    0.3992   0.6068: 100%|████████| 1525/1525 [09:15<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.327, Accuracy=0.617\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/9    0.2608: 100%|█████████████████| 3552/3552 [37:06<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] loss=0.3918, time=2226.5\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/9    0.5711   0.7776: 100%|████████| 1525/1525 [09:12<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.464, Accuracy=0.663\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/9    0.3273: 100%|█████████████████| 3552/3552 [36:36<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] loss=0.3705, time=2196.7\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/9    0.5086   0.7774: 100%|████████| 1525/1525 [07:05<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.514, Accuracy=0.721\n",
      "best fit so far=>saved\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/9    0.2940: 100%|█████████████████| 3552/3552 [30:40<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] loss=0.3531, time=1840.1\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/9    0.4949   0.7693: 100%|████████| 1525/1525 [06:47<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.470, Accuracy=0.714\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/9    0.3347: 100%|█████████████████| 3552/3552 [30:19<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] loss=0.3351, time=1819.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/9    0.5037   0.7265: 100%|████████| 1525/1525 [06:47<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.555, Accuracy=0.752\n",
      "best fit so far=>saved\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/9    0.1858: 100%|█████████████████| 3552/3552 [30:21<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] loss=0.3231, time=1821.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/9    0.5751   0.7750: 100%|████████| 1525/1525 [06:46<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.557, Accuracy=0.758\n",
      "best fit so far=>saved\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=patch_size, save_path=os.path.join(workspace_path, 'codes/tb_ckpt_hrnet_w48'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8c906b3"
   },
   "source": [
    "### 최고 성능 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1f298c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success\n"
     ]
    }
   ],
   "source": [
    "save_path=os.path.join(workspace_path, 'codes/tb_ckpt_hrnet_w48')\n",
    "\n",
    "checkpoint_path = os.path.join(save_path,'{}_best.pt'.format(model_name))\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "\n",
    "print('model load success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74453fb5"
   },
   "source": [
    "### 테스트 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "42e6ae95"
   },
   "outputs": [],
   "source": [
    "test_rgb_path = os.path.join(workspace_path, 'data/test/rgb')\n",
    "test_rgb_images = os.listdir(test_rgb_path)\n",
    "test_rgb_images = [os.path.join(test_rgb_path, x) for x in test_rgb_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dbeb921a"
   },
   "outputs": [],
   "source": [
    "#empty value\n",
    "test_label_path = os.path.join(workspace_path, 'data/test/label')\n",
    "try:\n",
    "    test_label_images = os.listdir(test_label_path)\n",
    "except:\n",
    "    test_label_images = []\n",
    "test_label_images = [os.path.join(test_label_path, x) for x in test_label_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1ba27f1e"
   },
   "outputs": [],
   "source": [
    "test_dataset = CloudDataset(test_rgb_images, test_label_images,\n",
    "                            transforms=val_transforms, is_train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a055ede"
   },
   "source": [
    "### 테스트 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eadca7d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 208/208 [00:28<00:00,  7.28it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "result_path = os.path.join(workspace_path, 'results')\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "    for i, (imgs, img_path) in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        if model_name == 'deeplabv3':\n",
    "            preds = model(imgs)['out']\n",
    "        elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "            preds = model(imgs)\n",
    "            h, w = preds.shape[2], preds.shape[3]\n",
    "        elif model_name == 'dilated_unet':\n",
    "            preds = model(imgs)\n",
    "        \n",
    "        preds = F.interpolate(preds, scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        pred_img = np.zeros((*list(preds.shape[2:]), 3), dtype=np.uint8)\n",
    "\n",
    "        _, idx = preds.squeeze(0).max(0)\n",
    "        pos = idx == 0\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 0]\n",
    "        pos = idx == 1\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 255]\n",
    "        pos = idx == 2\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 0]\n",
    "        pos = idx == 3\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 255]\n",
    "        \n",
    "#         pred_img = F.interpolate(pred_img, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "#         print(type(pred_img))\n",
    "        cv2.imwrite(os.path.join(result_path, os.path.basename(img_path[0])), pred_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18494383"
   },
   "source": [
    "### Run-Length Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1e8d274d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "f4ebad00"
   },
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "cd9e1cbb"
   },
   "outputs": [],
   "source": [
    "test_label_file_list = os.listdir(result_path)\n",
    "test_label_path_list = [os.path.join(result_path, x) for x in test_label_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "92c7170e"
   },
   "outputs": [],
   "source": [
    "rle_list = []\n",
    "for file_path in test_label_path_list:\n",
    "    img = cv2.imread(file_path)\n",
    "    rle = mask2rle(img)\n",
    "    rle_list.append(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9851d2ed"
   },
   "outputs": [],
   "source": [
    "my_dict = {'Image_Label':test_label_file_list, 'EncodedPixels':rle_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "b0873d66"
   },
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7c595d0d"
   },
   "outputs": [],
   "source": [
    "# my_df.to_csv(os.path.join(workspace_path, 'submission_hrnet_w48.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "0e74acfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Image_Label                                      EncodedPixels\n",
      "0     00914.png  1000001 339 1000651 62 1000763 5 1000858 78 10...\n",
      "1     00889.png  1008573 4 1009571 7 1010570 9 1011570 9 101257...\n",
      "2     00980.png  1059750 5 1060750 5 1061750 5 1062749 6 106374...\n",
      "3     00884.png  1000256 440 1000864 4 1000975 18 1001256 440 1...\n",
      "4     00971.png  1000685 35 1000888 11 1000909 25 1001685 35 10...\n",
      "..          ...                                                ...\n",
      "203   00952.png  1000929 7 1000956 23 1001929 7 1001956 23 1002...\n",
      "204   00902.png  1000582 24 1000861 17 1001582 24 1001861 17 10...\n",
      "205   00932.png  1000001 101 1000348 9 1000498 35 1000544 20 10...\n",
      "206   00913.png  1000098 30 1000632 17 1000688 27 1000741 24 10...\n",
      "207   00949.png  1095826 9 1096825 13 1097823 18 1098822 22 109...\n",
      "\n",
      "[208 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Image_Label                                      EncodedPixels\n",
      "0     00914.png  1000001 304 1000346 22 1000684 31 1000755 18 1...\n",
      "1     00889.png  1103115 3 1104112 7 1105109 12 1106108 14 1107...\n",
      "2     00980.png  1031780 2 1032780 3 1033781 3 1034781 5 103578...\n",
      "3     00884.png  1000265 326 1000614 78 1000848 153 1001265 326...\n",
      "4     00971.png  1000212 13 1000682 41 1000871 78 1001212 13 10...\n",
      "..          ...                                                ...\n",
      "203   00952.png  1022971 2 1023969 5 1024956 8 1024966 8 102595...\n",
      "204   00902.png  1000582 30 1000859 44 1001582 30 1001859 44 10...\n",
      "205   00932.png  1000001 72 1000078 23 1000340 61 1000417 52 10...\n",
      "206   00913.png  1000749 37 1001749 37 1002749 37 1003749 37 10...\n",
      "207   00949.png  1028333 18 1029329 25 1030283 5 1030324 32 103...\n",
      "\n",
      "[208 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_test = pd.read_csv(os.path.join(workspace_path, 'submission_dv550_wnrg.csv'))\n",
    "csv_test = pd.DataFrame(csv_test)\n",
    "print(csv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Image_Label                                      EncodedPixels\n",
      "0     00914.png  1000001 303 1000681 42 1000762 10 1000855 122 ...\n",
      "1     00889.png  1112101 4 1113092 16 1114088 22 1115086 25 111...\n",
      "2     00980.png  1037781 1 1038781 5 1039781 5 1040781 6 104178...\n",
      "3     00884.png  1000256 457 1000777 21 1000820 181 1001256 457...\n",
      "4     00971.png  1000689 21 1000851 106 1001689 21 1001851 106 ...\n",
      "..          ...                                                ...\n",
      "203   00952.png  1000929 63 1001929 63 1002928 64 1003926 66 10...\n",
      "204   00902.png  1000273 30 1000353 43 1000587 18 1000799 4 100...\n",
      "205   00932.png  1000001 99 1000345 28 1000394 73 1000473 33 10...\n",
      "206   00913.png  1000745 26 1000983 18 1001745 26 1001983 18 10...\n",
      "207   00949.png  1061230 5 1062229 8 1063228 12 1064227 15 1065...\n",
      "\n",
      "[208 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_test = pd.read_csv(os.path.join(workspace_path, 'submission_hrnet_w18_rgb400_ep40.csv'))\n",
    "csv_test = pd.DataFrame(csv_test)\n",
    "print(csv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
