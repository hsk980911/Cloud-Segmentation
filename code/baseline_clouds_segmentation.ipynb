{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJ_5vemHnXlZ"
   },
   "source": [
    "구글 드라이브 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-1-veNcnW6U"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1NrfEiTnlLS"
   },
   "source": [
    "폴더 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oW1RJXWnkxw"
   },
   "outputs": [],
   "source": [
    "# workspace_path = '/gdrive/My Drive/Colab Notebooks/CV2022/competition'  # 파일 업로드한 경로 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = '/app/HSK/CV'  # 파일 업로드한 경로 반영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86ea40c7"
   },
   "source": [
    "### 필요한 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRfwuEL2--n-"
   },
   "outputs": [],
   "source": [
    "!pip install albumentations==0.4.6\n",
    "!pip install   yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52bbfdfb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "649609b1"
   },
   "source": [
    "### 재구현 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c35eec19"
   },
   "outputs": [],
   "source": [
    "def init_seeds(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    if seed == 0:  # slower, more reproducible\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = False\n",
    "    else:  # faster, less reproducible\n",
    "        cudnn.deterministic = False\n",
    "        cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b90c4ec5"
   },
   "outputs": [],
   "source": [
    "init_seeds(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f8a343a"
   },
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "499b3f23"
   },
   "outputs": [],
   "source": [
    "rgb_path = os.path.join(workspace_path, 'data/train/rgb/')\n",
    "ngr_path = os.path.join(workspace_path, 'data/train/ngr/')\n",
    "label_path = os.path.join(workspace_path, 'data/train/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4e26b49"
   },
   "outputs": [],
   "source": [
    "rgb_images = os.listdir(rgb_path)\n",
    "rgb_images = [os.path.join(rgb_path,x) for x in rgb_images]\n",
    "ngr_images = os.listdir(ngr_path)\n",
    "ngr_images = [os.path.join(ngr_path, x) for x in ngr_images]\n",
    "label_images = os.listdir(label_path)\n",
    "label_images = [os.path.join(label_path, x) for x in label_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997d5237"
   },
   "source": [
    "### 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca96420c"
   },
   "outputs": [],
   "source": [
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, label_path, patch_size = 400, patch_stride = 100, is_train = True, cache_dir = './cache', transforms = None):\n",
    "        self.image_path = image_path\n",
    "        self.label_path = label_path\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_stride = patch_stride\n",
    "        self.is_train = is_train\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.patch_images = []\n",
    "        self.patch_labels = []\n",
    "        \n",
    "        \n",
    "        cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        if is_train:\n",
    "            for img_path in self.image_path:\n",
    "                img = cv2.imread(img_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'rgb_{os.path.splitext(os.path.basename(img_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_images.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "\n",
    "            for label_path in self.label_path:\n",
    "                img = cv2.imread(label_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'label_{os.path.splitext(os.path.basename(label_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_labels.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "        else:\n",
    "            self.patch_images = self.image_path\n",
    "            self.patch_labels = self.label_path\n",
    "    def __len__(self):\n",
    "        return len(self.patch_images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.patch_images[idx])\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = cv2.imread(self.patch_labels[idx])\n",
    "            # numpy arrays to tensors\n",
    "            h, w = label.shape[:2]\n",
    "        \n",
    "            target = np.zeros((h, w), dtype=np.uint8)\n",
    "            pos = np.where(np.all(label == [0, 0, 255], axis=-1))  # thick cloud\n",
    "            target[pos] = 1\n",
    "            pos = np.where(np.all(label == [0, 255, 0], axis=-1))  # thin cloud\n",
    "            target[pos] = 2\n",
    "            pos = np.where(np.all(label == [0, 255, 255], axis=-1))  # cloud shadow\n",
    "            target[pos] = 3\n",
    "        else:\n",
    "            target = None\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        if self.is_train:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, self.patch_images[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09d79e8b"
   },
   "source": [
    "### 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6ac4eae"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 10\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "patch_size = 400\n",
    "patch_stride = 100\n",
    "num_workers = 0\n",
    "\n",
    "num_classes = 4\n",
    "class_names = ['thick cloud', 'thin cloud', 'cloud shadow']\n",
    "\n",
    "train_data_rate = 0.7\n",
    "\n",
    "model_name = 'dilated_unet'\n",
    "\n",
    "loss_func = 'dice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e4513b1"
   },
   "source": [
    "### 데이터증대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17dc2c12"
   },
   "outputs": [],
   "source": [
    "class ImageAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.HorizontalFlip(p=0.5),\n",
    "                             A.VerticalFlip(p=0.5),\n",
    "                             A.ShiftScaleRotate(p=0.5),\n",
    "                             A.RandomBrightnessContrast(p=0.3),\n",
    "                             A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']\n",
    "\n",
    "class DefaultAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03a59423"
   },
   "outputs": [],
   "source": [
    "train_transforms = ImageAug()\n",
    "val_transforms = DefaultAug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2147f462"
   },
   "source": [
    "### 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98bed485"
   },
   "outputs": [],
   "source": [
    "#train dataset\n",
    "train_dataset = CloudDataset(rgb_images[:int(len(rgb_images)*train_data_rate)], label_images[:int(len(label_images)*train_data_rate)],\n",
    "                            transforms=train_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "#valid dataset\n",
    "val_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate):], label_images[int(len(label_images)*train_data_rate):],\n",
    "                            transforms=val_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cbab53"
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e54a2c7d"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIK90NknzGPn"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DilatedConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation, padding):\n",
    "        super(DilatedConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, dilation=dilation),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConcatDoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConcatDoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((skip, x), dim=1)\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class MyDilatedConvUNet(nn.Module):\n",
    "    def __init__(self, filters=44, depth=3, bottleneck_depth=6):\n",
    "        super(MyDilatedConvUNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.encoder_path = nn.ModuleList()\n",
    "        src_in_channels = 3     # Geo-TIFF has four channels (R, G, B, and NIR)\n",
    "        for d in range(depth):\n",
    "            in_channels = src_in_channels if d == 0 else filters * 2 ** (d-1)\n",
    "            self.encoder_path.append(\n",
    "                DoubleConvBlock(in_channels, filters * 2 ** d))\n",
    "        self.maxpool = nn.MaxPool2d(2, 2, padding=0)\n",
    "        self.bottleneck_path = nn.ModuleList()\n",
    "        for d in range(bottleneck_depth):\n",
    "            in_channels = filters * 2 ** (depth - 1) if d == 0 else filters * 2 ** depth\n",
    "            self.bottleneck_path.append(DilatedConvBlock(in_channels, filters * 2 ** depth, 2 ** d, 2 ** d))\n",
    "        self.decoder_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.decoder_path.append(ConcatDoubleConvBlock(in_channels, filters * 2 ** (depth - d - 1)))\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.up_path.append(nn.ConvTranspose2d(in_channels, filters * 2 ** (depth - d - 1),\n",
    "                                                        kernel_size=4, stride=2, padding=1))\n",
    "        out_channels = 4     # output channels (num_classes + 1(background))\n",
    "        self.last_conv = nn.Conv2d(filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = []\n",
    "        for block in self.encoder_path:\n",
    "            x = block(x)\n",
    "            skip.append(x)\n",
    "            x = self.maxpool(x)\n",
    "        dilated = []\n",
    "        for block in self.bottleneck_path:\n",
    "            x = block(x)\n",
    "            dilated.append(x)\n",
    "        x = torch.stack(dilated, dim=-1).sum(dim=-1)  # sum over list\n",
    "\n",
    "        # up-sampling and double convolutions\n",
    "        for d in range(self.depth):\n",
    "            x = self.up_path[d](x)\n",
    "            x = self.decoder_path[d](x, skip[-(d+1)])\n",
    "\n",
    "        return self.last_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e3d9a09"
   },
   "outputs": [],
   "source": [
    "# method for hrnet init\n",
    "'''\n",
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "_C = CN()\n",
    "\n",
    "_C.OUTPUT_DIR = ''\n",
    "_C.LOG_DIR = ''\n",
    "_C.GPUS = (0,)\n",
    "_C.WORKERS = 4\n",
    "_C.PRINT_FREQ = 20\n",
    "_C.AUTO_RESUME = False\n",
    "_C.PIN_MEMORY = True\n",
    "_C.RANK = 0\n",
    "\n",
    "# Cudnn related params\n",
    "_C.CUDNN = CN()\n",
    "_C.CUDNN.BENCHMARK = True\n",
    "_C.CUDNN.DETERMINISTIC = False\n",
    "_C.CUDNN.ENABLED = True\n",
    "\n",
    "# common params for NETWORK\n",
    "_C.MODEL = CN()\n",
    "_C.MODEL.NAME = 'seg_hrnet'\n",
    "_C.MODEL.PRETRAINED = ''\n",
    "_C.MODEL.EXTRA = CN(new_allowed=True)\n",
    "\n",
    "_C.LOSS = CN()\n",
    "_C.LOSS.USE_OHEM = False\n",
    "_C.LOSS.OHEMTHRES = 0.9\n",
    "_C.LOSS.OHEMKEEP = 100000\n",
    "_C.LOSS.CLASS_BALANCE = True\n",
    "\n",
    "# DATASET related params\n",
    "_C.DATASET = CN()\n",
    "_C.DATASET.ROOT = ''\n",
    "_C.DATASET.DATASET = 'cityscapes'\n",
    "_C.DATASET.NUM_CLASSES = 19\n",
    "_C.DATASET.TRAIN_SET = 'list/cityscapes/train.lst'\n",
    "_C.DATASET.EXTRA_TRAIN_SET = ''\n",
    "_C.DATASET.TEST_SET = 'list/cityscapes/val.lst'\n",
    "\n",
    "# training\n",
    "_C.TRAIN = CN()\n",
    "\n",
    "_C.TRAIN.IMAGE_SIZE = [1024, 512]  # width * height\n",
    "_C.TRAIN.BASE_SIZE = 2048\n",
    "_C.TRAIN.DOWNSAMPLERATE = 1\n",
    "_C.TRAIN.FLIP = True\n",
    "_C.TRAIN.MULTI_SCALE = True\n",
    "_C.TRAIN.SCALE_FACTOR = 16\n",
    "\n",
    "_C.TRAIN.LR_FACTOR = 0.1\n",
    "_C.TRAIN.LR_STEP = [90, 110]\n",
    "_C.TRAIN.LR = 0.01\n",
    "_C.TRAIN.EXTRA_LR = 0.001\n",
    "\n",
    "_C.TRAIN.OPTIMIZER = 'sgd'\n",
    "_C.TRAIN.MOMENTUM = 0.9\n",
    "_C.TRAIN.WD = 0.0001\n",
    "_C.TRAIN.NESTEROV = False\n",
    "_C.TRAIN.IGNORE_LABEL = -1\n",
    "\n",
    "_C.TRAIN.BEGIN_EPOCH = 0\n",
    "_C.TRAIN.END_EPOCH = 484\n",
    "_C.TRAIN.EXTRA_EPOCH = 0\n",
    "\n",
    "_C.TRAIN.RESUME = False\n",
    "\n",
    "_C.TRAIN.BATCH_SIZE_PER_GPU = 32\n",
    "_C.TRAIN.SHUFFLE = True\n",
    "# only using some training samples\n",
    "_C.TRAIN.NUM_SAMPLES = 0\n",
    "\n",
    "# testing\n",
    "_C.TEST = CN()\n",
    "\n",
    "_C.TEST.IMAGE_SIZE = [2048, 1024]  # width * height\n",
    "_C.TEST.BASE_SIZE = 2048\n",
    "\n",
    "_C.TEST.BATCH_SIZE_PER_GPU = 32\n",
    "# only testing some samples\n",
    "_C.TEST.NUM_SAMPLES = 0\n",
    "\n",
    "_C.TEST.MODEL_FILE = ''\n",
    "_C.TEST.FLIP_TEST = False\n",
    "_C.TEST.MULTI_SCALE = False\n",
    "_C.TEST.SCALE_LIST = [1]\n",
    "\n",
    "# debug\n",
    "_C.DEBUG = CN()\n",
    "_C.DEBUG.DEBUG = False\n",
    "_C.DEBUG.SAVE_BATCH_IMAGES_GT = False\n",
    "_C.DEBUG.SAVE_BATCH_IMAGES_PRED = False\n",
    "_C.DEBUG.SAVE_HEATMAPS_GT = False\n",
    "_C.DEBUG.SAVE_HEATMAPS_PRED = False\n",
    "\n",
    "\n",
    "def update_config(file):\n",
    "    cfg = _C.clone()\n",
    "    cfg.defrost()\n",
    "    cfg.merge_from_file(file)\n",
    "    cfg.freeze()\n",
    "    return cfg\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78338b36"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "if model_name == 'deeplabv3':\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=4)\n",
    "#elif model_name == 'hrnet_w18':\n",
    "#    hrnet_cfg = update_config(os.path.join(workspace_path, 'models/hrnet_w18_config.yaml'))\n",
    "#    model = get_seg_model(hrnet_cfg)\n",
    "#elif model_name == 'hrnet_w48':\n",
    "#    hrnet_cfg = update_config(os.path.join(workspace_path, 'models/hrnet_w48_config.yaml'))\n",
    "#    model = get_seg_model(hrnet_cfg)\n",
    "elif model_name == 'dilated_unet':\n",
    "    model = MyDilatedConvUNet()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('number of parameters: ', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "467743f7"
   },
   "source": [
    "### Opimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "314acf1e"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuJfaks1zbtC"
   },
   "source": [
    "### 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c124f5df"
   },
   "outputs": [],
   "source": [
    "def fitness_test(true, pred, num_classes=4):\n",
    "    eps = 1e-7\n",
    "    true_one_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_one_hot = true_one_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "    pred_max = pred.argmax(1)      # (B, C, H, W) to (B, H, W)\n",
    "    pix_acc = (true == pred_max.unsqueeze(1)).sum().float().div(true.nelement())\n",
    "    pred_one_hot = F.one_hot(pred_max, num_classes=num_classes)   # (B, H, W) to (B, H, W, C)\n",
    "    pred_one_hot = pred_one_hot.permute(0, 3, 1, 2)   # (B, H, W, C) to (B, C, H, W)\n",
    "\n",
    "    true_one_hot = true_one_hot.type(pred_one_hot.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))  # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(pred_one_hot & true_one_hot, dims)\n",
    "    union = torch.sum(pred_one_hot | true_one_hot, dims)\n",
    "    m_iou = (intersection / (union + eps)).mean()\n",
    "\n",
    "    return m_iou.item(), pix_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v74FWycdzdev"
   },
   "outputs": [],
   "source": [
    "# Loss 함수 정의\n",
    "def ce_loss(true, logits, ignore=255):\n",
    "    \"\"\"Computes the weighted multi-class cross-entropy loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        ignore: the class index to ignore.\n",
    "    Returns:\n",
    "        ce_loss: the weighted multi-class cross-entropy loss.\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(\n",
    "        logits.float(),\n",
    "        true.squeeze(1).long(),    # [B, H, W]\n",
    "        ignore_index=ignore,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        # true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))        # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "def jaccard_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d1af165"
   },
   "source": [
    "### 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bad17d99"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=400, use_scheduler=False, save_path='./ckpt'):\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    if use_scheduler:\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "    start_epoch = 0\n",
    "    resume = True\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    weight_file = save_path + '/{}.pt'.format(model_name)\n",
    "\n",
    "    best_fit = 0.0\n",
    "    num_epochs = epochs\n",
    "\n",
    "    if resume:\n",
    "        if os.path.exists(weight_file):\n",
    "            checkpoint = torch.load(weight_file)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_fit = checkpoint['best_fit']\n",
    "            print(\"Starting training for %g epochs...\" % start_epoch)\n",
    "\n",
    "    # Start training\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        # loss, metric = train_one_epoch(model, optimizer, dataloader, device, epoch)\n",
    "        t0 = time.time()\n",
    "        loss = train_one_epoch(model, optimizer, train_dataloader, loss_func, device, epoch, num_epochs)\n",
    "        t1 = time.time()\n",
    "        print('[Epoch %g] loss=%.4f, time=%.1f' % (epoch, loss.item(), t1 - t0))\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step(loss)\n",
    "        #tb_writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        state = {'model_name': model_name, 'epoch': epoch, 'best_fit': best_fit, 'model': model.state_dict()}\n",
    "        torch.save(state, weight_file)\n",
    "\n",
    "        #tb_writer.add_scalar('train_epoch_loss', loss, epoch)\n",
    "\n",
    "        # validation\n",
    "        patch_size = patch_size\n",
    "        fit = val_one_epoch(model, val_dataloader, device, epoch, num_epochs, patch_size)\n",
    "        if fit > best_fit:\n",
    "            print(\"best fit so far=>saved\")\n",
    "            torch.save(state, save_path + '/{}_best.pt'.format(model_name))\n",
    "            best_fit = fit\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, loss_func, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    losses = np.array([])\n",
    "    metrics = np.array([])\n",
    "    bi0 = epoch * len(data_loader)  # batch index\n",
    "\n",
    "    print(('\\n' + '%10s' * 2) % ('Epoch', 'loss'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0)\n",
    "    pbar.set_description(s)\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        if model_name == 'deeplabv3':\n",
    "            preds = model(imgs)['out']\n",
    "            targets = targets.long()\n",
    "        elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "            preds = model(imgs)\n",
    "            h, w = preds.shape[2], preds.shape[3]\n",
    "            targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n",
    "        elif model_name == 'dilated_unet':\n",
    "            preds = model(imgs)\n",
    "            targets = targets.long()\n",
    "            \n",
    "        if loss_func == 'jaccard':\n",
    "            loss = jaccard_loss(targets, preds)\n",
    "        elif loss_func == 'dice':\n",
    "            loss = dice_loss(targets, preds)\n",
    "        elif loss_func == 'ce':\n",
    "            loss = ce_loss(targets, preds)\n",
    "        else:\n",
    "            print('unsupported loss function')\n",
    "            exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # cv2_imshow(imgs[0], preds[0])\n",
    "            losses = np.append(losses, loss.item())\n",
    "\n",
    "            s = ('%10s' + '%10.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), loss.item())\n",
    "            pbar.set_description(s)\n",
    "            bi = bi0 + i\n",
    "            #tb_writer.add_scalar('train_batch_loss', loss.item(), bi)\n",
    "\n",
    "    epoch_loss = losses.mean()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def val_one_epoch(model, data_loader, device, epoch, num_epochs, patch_size):\n",
    "    model.eval()\n",
    "    m_iou_list = np.array([])\n",
    "    pix_acc_list = np.array([])\n",
    "\n",
    "    print(('\\n' + '%10s' * 3) % ('Epoch(V)', 'mIOU', 'Accuracy'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0, 0.0)\n",
    "    pbar.set_description(s)\n",
    "\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            if model_name == 'deeplabv3':\n",
    "                preds = model(imgs)['out']\n",
    "                targets = targets.long()\n",
    "            elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "                preds = model(imgs)\n",
    "                h, w = preds.shape[2], preds.shape[3]\n",
    "                targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n",
    "            elif model_name == 'dilated_unet':\n",
    "                preds = model(imgs)\n",
    "                targets = targets.long()\n",
    "\n",
    "            m_iou, pix_acc = fitness_test(targets, preds)\n",
    "\n",
    "            s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), m_iou, pix_acc)\n",
    "            pbar.set_description(s)\n",
    "            m_iou_list = np.append(m_iou_list, m_iou)\n",
    "            pix_acc_list = np.append(pix_acc_list, pix_acc)\n",
    "    val_m_iou_mean = m_iou_list.mean()\n",
    "    val_pix_acc_mean = pix_acc_list.mean()\n",
    "    print('[V] mIOU={:.3f}, Accuracy={:.3f}'.format(val_m_iou_mean, val_pix_acc_mean))\n",
    "    #tb_writer.add_scalar('val_epoch_m_iou', val_m_iou_mean, epoch)\n",
    "    #tb_writer.add_scalar('val_epoch_pix_acc', val_pix_acc_mean, epoch)\n",
    "    return val_pix_acc_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "600d9790"
   },
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b74e3dff"
   },
   "outputs": [],
   "source": [
    "train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=patch_size, save_path='/app/HSK/CV/ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8c906b3"
   },
   "source": [
    "### 최고 성능 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f298c14"
   },
   "outputs": [],
   "source": [
    "save_path=os.path.join(workspace_path, 'ckpt')\n",
    "\n",
    "checkpoint_path = os.path.join(save_path,'{}_best.pt'.format(model_name))\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "\n",
    "print('model load success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74453fb5"
   },
   "source": [
    "### 테스트 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42e6ae95"
   },
   "outputs": [],
   "source": [
    "test_rgb_path = os.path.join(workspace_path, 'data/test/rgb')\n",
    "test_rgb_images = os.listdir(test_rgb_path)\n",
    "test_rgb_images = [os.path.join(test_rgb_path, x) for x in test_rgb_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbeb921a"
   },
   "outputs": [],
   "source": [
    "#empty value\n",
    "test_label_path = os.path.join(workspace_path, 'data/test/label')\n",
    "try:\n",
    "    test_label_images = os.listdir(test_label_path)\n",
    "except:\n",
    "    test_label_images = []\n",
    "test_label_images = [os.path.join(test_label_path, x) for x in test_label_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ba27f1e"
   },
   "outputs": [],
   "source": [
    "test_dataset = CloudDataset(test_rgb_images, test_label_images,\n",
    "                            transforms=val_transforms, is_train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a055ede"
   },
   "source": [
    "### 테스트 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eadca7d5"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "result_path = os.path.join(workspace_path, 'results')\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "    for i, (imgs, img_path) in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        if model_name == 'deeplabv3':\n",
    "            preds = model(imgs)['out']\n",
    "        #elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "        #    preds = model(imgs)\n",
    "        #    h, w = preds.shape[2], preds.shape[3]\n",
    "        elif model_name == 'dilated_unet':\n",
    "            preds = model(imgs)\n",
    "        \n",
    "        pred_img = np.zeros((*list(preds.shape[2:]), 3), dtype=np.uint8)\n",
    "        _, idx = preds.squeeze(0).max(0)\n",
    "        pos = idx == 0\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 0]\n",
    "        pos = idx == 1\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 255]\n",
    "        pos = idx == 2\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 0]\n",
    "        pos = idx == 3\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 255]\n",
    "        \n",
    "        cv2.imwrite(os.path.join(result_path, os.path.basename(img_path[0])), pred_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18494383"
   },
   "source": [
    "### Run-Length Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e8d274d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4ebad00"
   },
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd9e1cbb"
   },
   "outputs": [],
   "source": [
    "test_label_file_list = os.listdir(result_path)\n",
    "test_label_path_list = [os.path.join(result_path, x) for x in test_label_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92c7170e"
   },
   "outputs": [],
   "source": [
    "rle_list = []\n",
    "for file_path in test_label_path_list:\n",
    "    img = cv2.imread(file_path)\n",
    "    rle = mask2rle(img)\n",
    "    rle_list.append(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9851d2ed"
   },
   "outputs": [],
   "source": [
    "my_dict = {'Image_Label':test_label_file_list, 'EncodedPixels':rle_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0873d66"
   },
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c595d0d"
   },
   "outputs": [],
   "source": [
    "my_df.to_csv(os.path.join(workspace_path, 'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e74acfe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "baseline-clouds-segmentation-colab-ver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
